# https://s3.amazonaws.com/tcmg476/http_access_log

#Questions (Output to screen)
# How many total requests were made in the time period represented in the log?
# How many requests were made on each day? per week? per month?
# What percentage of the requests were not successful (any 4xx status code)?
# What percentage of the requests were redirected elsewhere (any 3xx codes)?
# What was the most-requested file?
# What was the least-requested file?

# Logs should be broken into separate files by month 
# Write the 12 files to this directory (~/Desktop/Project3)

#import urllib.request #downloading a file over the internet
#import re #regular expressions
#from pathlib import Path
#import operator


#log_url = 'https://s3.amazonaws.com/tcmg476/http_access_log'
#local_log_file = Path("logfile.txt")

# Retrieve File (below). I have already downloaded it :) add a conditional to check for logfile.txt so we don't have to get it every time.
# urllib.request.urlretrieve(log_url, 'logfile.txt')
#if local_log_file.is_file():
    #file exists
 #   print("Log file exists!\n")
#else: #file does not exist
#    print("Downloading log file now!\n")
 #   urllib.request.urlretrieve(log_url, 'logfile.txt')
    
#1?
#SELECT a.cs-uri-stem, COUNT(*) as total-requests, b.all-requests
#FROM long_running_pages AS a
#JOIN all_pages_grouped b ON ( a.cs-uri-stem = b.cs-uri-stem)
#GROUP BY a.cs-uri-stem
 
 #new new

import urllib2  # the lib that handles the url stuff
import re
from collections import Counter

count =0
data = urllib2.urlopen('https://s3.amazonaws.com/tcmg476/http_access_log') # it's a file like object and works just like a file
datecount = {} #Dictionary to store the count for every date
monthcount = {} #Dictionary to store the count for every month
errorcount=0
newcount=0
for line in data: 
    #Example of one line
    #'local - - [25/Oct/1994:10:08:07 -0600] "GET index.html HTTP/1.0" 200 3185\n'
    
	#CODE FOR #2
    count+=1
    left=line.find('[')
    right=line.find(':')
    date=line[left+1:right]
    if not date[0].isdigit(): #Something wrong with this line
        continue #skip
    if not date in datecount.keys():
        datecount[date]=1 #Set initial value
    else:
        datecount[date]+=1 #Increment value

    datewords=date.split('/')
    try:
        month=datewords[1]
        if not month in monthcount.keys():
            monthcount[month]=1 #Set initial value
        else:
            monthcount[month]+=1 #Increment value
    except:
        continue
		
	 #CODE FOR #3 AND #4
    words=line.split()
    try:
        code=int(words[-2])
        if code>=400 and code<500:
            errorcount+=1
        if code>=300 and code<400:
            newcount+=1
    except:
        continue
		
#5 & 6 sorta
mydata = data.read()
words = (re.findall(r'"(.*?)"', mydata))
c = Counter(words)
request_count = c.most_common(1)
request_count = request_count[0]
request = request_count[0]
print("maximum no of requests: ", request)

#counter = collections.Counter(clean_log)
#get the most popular 
#for count in counter.most_common(1):
 #   print(str(count[1]) + "	" + str(count[0]))

#logfile.close()
	
 #ANSWERING #1  
print('total requests = {}'.format(count)) #for taking the amount of lines in logfile

#ANSWERING #2
#for date in datecount.keys():
    #print('total for {} = {}'.format(date,datecount[date]))
#for month in monthcount.keys():
    #print('total for {} = {}'.format(month,monthcount[month]))

#ANSWERING #3 AND #4
print 'Amount of Sucessful Requests: ', errorcount
print 'Amount of Unsucessful Requests: ', newcount

#IMPORTING TO CSV
import csv

result = {}
with open('output.csv', 'w') as csvfile:
    csvwriter = csv.writer(csvfile)
    for row in result.items():
        csvwriter.writerow(row)
